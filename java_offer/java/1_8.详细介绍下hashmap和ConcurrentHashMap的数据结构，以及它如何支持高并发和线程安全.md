# 一、HashMap

好的，我们来详细解析一下 HashMap 的数据结构。它是面试中最常被问及的核心数据结构之一，理解其设计精髓至关重要。

### 一、核心概览：数组 + 链表 + 红黑树

HashMap 在 JDK 1.8 之后的数据结构可以概括为：**一个 Node 类型的数组，数组的每个位置被称为一个 "桶"（bucket）或 "槽"（slot）。当发生哈希冲突时，在同一个桶位上会形成链表；当链表长度超过阈值时，链表会转换为红黑树，以提升查询效率。**

所以，它的主体结构是：**数组 + 链表 + 红黑树**。

---

### 二、核心组件详解

#### 1. 数组（Table）
*   **作用**：这是 HashMap 的骨架和主体，提供了 O(1) 时间复杂度的快速访问能力。
*   **细节**：
    *   数组的初始长度默认为 **16**。
    *   数组的长度 **必须是 2 的幂**（如 16, 32, 64）。这样设计的目的非常巧妙，我们后面会解释。

#### 2. 节点（Node）
数组中的每个元素都是一个 `Node` 对象（在链表情况下）或 `TreeNode` 对象（在红黑树情况下）。我们先看 `Node`：
```java
static class Node<K,V> implements Map.Entry<K,V> {
    final int hash; // 键的哈希值，用于比较和计算索引
    final K key;    // 键
    V value;        // 值
    Node<K,V> next; // 指向下一个节点的指针，用于形成链表
}
```
一个 `Node` 就是一个简单的键值对，它通过 `next` 指针可以指向下一个 `Node`，从而形成单向链表。

#### 3. 链表
*   **何时产生**：当两个或更多个键（key）通过哈希函数计算出的**数组索引相同**时，就发生了 **"哈希冲突"**。HashMap 的解决方法是 **"链地址法"**，即将这些发生冲突的 `Node` 通过 `next` 指针连接成一个单向链表，挂在数组的同一个桶位上。
*   **查找**：在链表中查找元素需要遍历，时间复杂度为 O(n)。

#### 4. 红黑树（TreeNode）
*   **何时产生**：为了优化在极端情况下（大量键都哈希到同一个桶）链表过长导致的性能退化，JDK 1.8 引入了红黑树。当链表的长度 **超过 8** 并且 **当前数组的长度大于等于 64** 时，链表就会转换为红黑树。
*   **何时退化回链表**：当红黑树中的节点数量 **小于等于 6** 时，红黑树会退化为链表。
*   **优势**：红黑树是一种自平衡的二叉查找树，它能将最坏情况下的查找、插入、删除时间复杂度从 O(n) 优化到 O(log n)。

---

### 三、HashMap 的核心工作原理

#### 1. `put(key, value)` 过程
1.  **计算哈希值**：首先调用 `key.hashCode()` 方法计算出原始的哈希值 `h`。
2.  **扰动函数**：为了减少哈希冲突，HashMap 并不是直接使用原始的哈希值，而是进行了一次 **高16位异或低16位** 的扰动计算：`(h = key.hashCode()) ^ (h >>> 16)`。这样做的目的是将高位的特征融入到低位中，使得哈希分布更加均匀。
3.  **计算数组索引**：使用扰动后的哈希值 `hash` 和数组长度 `length` 计算索引：`index = (length - 1) & hash`。
    *   **为什么数组长度是 2 的幂？** 因为 `length - 1` 的二进制形式永远是全 `1`（比如 16-1=15，二进制为 `1111`）。这样，`(length - 1) & hash` 操作就等价于 `hash % length`（取模运算），但位运算 `&` 的效率远高于取模 `%`。这保证了计算出的索引一定在数组范围内 `[0, length-1]`。
4.  **放入数组/处理冲突**：
    *   如果计算出的索引位置为 `null`，直接创建一个新 `Node` 放入。
    *   如果不为 `null`（发生了哈希冲突）：
        *   检查第一个节点的 `key` 是否与要插入的 `key` 相同（通过 `equals` 和 `hashCode` 判断）。如果相同，则覆盖其 `value`。
        *   如果不同，判断该节点是 `TreeNode` 还是 `Node`。
        *   如果是 `TreeNode`，则调用红黑树的 `putTreeVal` 方法插入。
        *   如果是 `Node`，则遍历链表。如果在遍历过程中找到相同的 `key`，则覆盖；如果没找到，则将新节点插入到链表**末尾**（JDK1.7是头插法，1.8改为了尾插法，避免在多线程下产生环形链表）。插入后，如果链表长度达到 8，则调用 `treeifyBin()` 方法判断是否需要树化。

#### 2. `get(key)` 过程
1.  同样，先计算 `key` 的哈希值，然后通过 `(length - 1) & hash` 计算出索引。
2.  找到数组对应的桶。
    *   如果该桶的第一个节点就是要找的（`hash` 和 `key` 都匹配），直接返回。
    *   如果不是，判断是红黑树还是链表，然后按照对应的数据结构进行查找。

#### 3. 扩容（Rehashing）机制
当 HashMap 中的元素数量超过 **数组长度 × 负载因子（Load Factor）** 时，就会进行扩容。默认负载因子是 **0.75**，默认初始长度是 **16**。
*   **触发条件**：当 `size > capacity * loadFactor` 时扩容。例如，默认情况下，当 `size > 16 * 0.75 = 12` 时，数组就会扩容。
*   **扩容操作**：
    1.  创建一个新的数组，长度是原数组的 **2 倍**（保持 2 的幂）。
    2.  遍历旧数组的每一个桶和其中的每一个节点（链表或树），重新计算每个节点在新数组中的索引位置。
        *   **JDK 1.8 的优化**：由于新数组长度是原来的 2 倍，所以 `newIndex = (newLength - 1) & hash`。观察这个计算，因为 `newLength - 1` 只是比 `oldLength - 1` 在高位多了一个 `1`，所以节点的新索引要么等于**原索引**，要么等于 **原索引 + 旧数组长度**。这样就不用重新计算哈希，只需看原哈希值新增的那个比特位是 0 还是 1，极大地提升了扩容效率。
    3.  将节点移动到新数组的对应位置。

---

### 四、关键特性总结

| 特性 | 说明 |
| :--- | :--- |
| **数据结构** | 数组 + 链表 + 红黑树（JDK 1.8+） |
| **初始容量** | 16 |
| **负载因子** | 0.75（时间与空间的权衡） |
| **扩容机制** | 当 `size > capacity * loadFactor` 时，扩容为原来的 2 倍 |
| **树化条件** | 链表长度 > 8 **且** 数组容量 >= 64 |
| **链表化条件** | 红黑树节点数 <= 6 |
| **线程安全** | **不安全**。多线程环境下推荐使用 `ConcurrentHashMap`。 |
| **键/值限制** | 键和值都可以为 `null`（`HashTable` 不允许） |
| **哈希计算** | 使用 `(h = key.hashCode()) ^ (h >>> 16)` 进行扰动 |

### 五、为什么这么设计？

1.  **为什么用数组？** 为了通过哈希值 O(1) 时间复杂度定位元素。
2.  **为什么用链表？** 为了解决哈希冲突，这是一种简单有效的方案。
3.  **为什么引入红黑树？** 防止在哈希攻击或不良哈希函数的情况下，链表过长导致性能从 O(1) 退化为 O(n)。红黑树将最坏情况提升到了 O(log n)。
4.  **为什么负载因子是 0.75？** 这是空间和时间成本的一个折衷。值太小（如0.5）会导致空间浪费和频繁扩容；值太大（如1.0）会导致哈希冲突概率增加，链表/树变长，查询效率降低。
5.  **为什么长度是 2 的幂？** 为了高效计算索引 `(n-1) & hash`，同时保证扩容时节点的新位置可以通过位运算快速确定。

# 二、详细介绍下ConcurrentHashMa的数据结构，以及它如何支持高并发和线程安全

好的，我们来详细解析 **ConcurrentHashMap** 的数据结构及其高并发、线程安全的实现原理。它是 Java 并发编程中最重要的容器类之一。

### 一、核心设计思想与演进

ConcurrentHashMap（后文简称 CHM）的设计目标是在保证线程安全的同时，提供尽可能高的读写性能。它的设计哲学是 **"锁分离"** 和 **"锁细化"**，与 Hashtable 那种全局使用一把锁的粗粒度方式完全不同。

*   **JDK 1.7**：使用 **分段锁（Segment）**，相当于将整个 Map 分成多个小的 Hashtable。
*   **JDK 1.8 及之后**：摒弃了分段锁，采用 **`Node数组 + 链表 + 红黑树`** 的结构，并发控制使用 **`synchronized` + `CAS`** 实现，粒度更细，性能更高。

我们主要讲解目前主流的 **JDK 1.8+ 的实现**。

---

### 二、JDK 1.8+ 的数据结构

CHM 在 1.8 之后，其基本数据结构与 HashMap 非常相似，这也是它易于理解的原因。

**主体结构：Node 数组 + 链表 + 红黑树**

1.  **`Node` 数组（Table）**：
    *   底层依然是一个 `Node` 类型的数组，每个 `Node` 代表一个键值对。
    ```java
    static class Node<K,V> implements Map.Entry<K,V> {
        final int hash;
        final K key;
        volatile V val;    // 注意：value 被 volatile 修饰，保证可见性
        volatile Node<K,V> next; // next 指针也是 volatile 的
    }
    ```
    *   关键点：`val` 和 `next` 字段都用 `volatile` 修饰，这保证了在多线程环境下，当一个线程修改了某个节点的值或链表结构时，其他线程能立即看到这个变化。

2.  **链表**：解决哈希冲突的方式与 HashMap 相同，也是链地址法。

3.  **红黑树（TreeBin）**：
    *   当链表长度超过阈值（默认8）且数组容量达到一定大小（默认64）时，链表会转换为红黑树。
    *   注意：CHM 中并不是直接存储 `TreeNode`，而是用了一个特殊的包装节点 **`TreeBin`** 来作为红黑树的根节点，它内部维护了红黑树的根，并持有锁状态，用于控制树的写操作。

---

### 三、如何支持高并发和线程安全？（核心原理）

JDK 1.8 的 CHM 通过 **`CAS`（无锁乐观锁）**、**`synchronized`（悲观锁）** 和 **`volatile`** 三种机制的精妙配合来实现高并发线程安全。

#### 1. 初始化与扩容时的线程安全（`CAS`）

`CAS` 是一种乐观锁，它假定竞争不总是发生，因此在更新数据时先比较旧值是否发生变化，没变化才更新。这种操作不需要阻塞线程，效率极高。

*   **数组初始化**：
    ```java
    private final Node<K,V>[] initTable() {
        while (tab == null) {
            // 使用 CAS 操作设置 sizeCtl 标志，只有一个线程能成功
            if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {
                try {
                    // 成功获取初始化权的线程负责创建数组
                    if (tab == null) { ... }
                } finally {
                    sizeCtl = sc;
                }
            }
        }
    }
    ```
    *   多个线程可能同时发现数组为空，但通过 `CAS` 争抢一个初始化标志位，只有一个线程能成功执行初始化，其他线程则自旋等待。

*   **`put` 操作中插入新节点**：
    *   当要向一个空的桶（数组位置）插入新节点时，不会直接上锁，而是使用 `CAS` 操作去写入新节点。
    ```java
    else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
        // 如果桶是空的，使用 CAS 尝试放入新节点
        if (casTabAt(tab, i, null, new Node<K,V>(hash, key, value)))
            break; // CAS 成功，插入完成
    }
    ```
    *   如果 `CAS` 失败，说明有其他线程抢先在这个位置插入了节点，当前线程会进入下一轮循环重试。

**`CAS` 的优势**：在无竞争或低竞争的情况下，性能极高，避免了用户态到内核态的切换开销。

#### 2. 更新已有节点的线程安全（`synchronized`）

当发生哈希冲突，需要操作链表或红黑树时，`CAS` 就不够用了，此时使用 **`synchronized`** 对链表的头节点（或树的根节点 `TreeBin`）进行加锁。

```java
// f 是链表在数组中的头节点
synchronized (f) {
    // 再次检查头节点是否被其他线程修改
    if (tabAt(tab, i) == f) {
        // 遍历链表，进行插入或更新
        // 或者操作红黑树
    }
}
```

**为什么 `synchronized` 性能依然很高？**
1.  **锁粒度极细**：锁的对象是**每个桶的头节点**。这意味着，只要多个线程操作的 key 分布在不同的桶上，它们就可以完全并行，互不干扰。这大大降低了锁的竞争概率。
2.  **锁优化**：现代 JVM 对 `synchronized` 做了大量优化，如偏向锁、轻量级锁、锁消除、锁粗化等，使得在竞争不激烈的情况下，`synchronized` 的性能开销已经非常小。

#### 3. 读操作的线程安全（`volatile` + `Unsafe`）

**`get` 操作完全不需要加锁！** 这是 CHM 实现高并发读的关键。

*   **可见性保证**：因为 `Node` 的 `value` 和 `next` 指针都被 `volatile` 修饰，所以当一个线程修改了某个节点的值或链表结构后，另一个线程在读取时能立即看到最新的结果。
*   **原子性读取**：CHM 使用 `Unsafe.getObjectVolatile` 来直接从主内存中原子性地读取数组中的元素和节点的内容，避免了读到脏数据。

```java
// 读取 tab 数组中 i 位置的值，具有 volatile 读的语义
static final <K,V> Node<K,V> tabAt(Node<K,V>[] tab, int i) {
    return (Node<K,V>)U.getObjectVolatile(tab, ((long)i << ASHIFT) + ABASE);
}
```

这种无锁读的设计，使得读操作可以和任何不冲突的写操作并发执行，性能极高。

---

### 四、关键操作流程

#### `put(key, value)` 流程
1.  计算 key 的 hash。
2.  进入一个自旋循环（`for` loop）。
3.  如果数组未初始化，则先初始化。
4.  根据 hash 找到对应的桶 `i`。
5.  如果桶 `i` 为空，使用 `CAS` 插入新节点，成功则退出。
6.  如果桶 `i` 不为空（可能是 `Node` 链表头或 `TreeBin`）：
    *   如果桶的 `hash` 为 `-1`，表示正在扩容，当前线程会协助扩容。
    *   否则，使用 `synchronized` 锁住这个桶的头节点 `f`。
        *   如果是链表，遍历并插入/更新。
        *   如果是红黑树，调用 `TreeBin` 的 `putTreeVal` 方法。
7.  判断是否需要树化。
8.  最后，检查容量是否超过阈值，如果需要则触发扩容。

#### 扩容机制（协助扩容）
CHM 的扩容机制非常精妙，它支持 **多线程协同扩容**。
*   当某个线程触发扩容时，它会创建一个新的、容量翻倍的新数组。
*   在数据迁移过程中，它并不是一次性完成，而是处理一个桶，就将这个桶的头节点标记为一个 **`ForwardingNode`** 节点（其 `hash` 值为 `-1`）。
*   其他线程在执行 `put` 或 `get` 操作时，如果发现某个桶的头节点是 `ForwardingNode`，就知道当前 Map 正在扩容。
    *   `get` 操作：会直接到新数组中去查找。
    *   `put` 操作：这个线程不会阻塞等待，而是**主动帮助进行数据迁移**，完成一部分桶的迁移工作后再继续自己的 `put` 操作。
*   这种 "人人为我，我为人人" 的设计，将扩容的压力分摊到了多个线程上，大大提高了扩容速度，避免了单个线程长时间阻塞。

---

### 五、与 Hashtable 和 HashMap 的对比

| 特性 | Hashtable | HashMap | ConcurrentHashMap (JDK 1.8) |
| :--- | :--- | :--- | :--- |
| **线程安全** | 是（全局锁 `synchronized`） | 否 | 是（桶级锁 `synchronized` + `CAS`） |
| **锁粒度** | 整个对象（粗粒度） | 无锁 | 单个桶（细粒度） |
| **读性能** | 低（全表锁） | 高（无锁） | **极高（完全无锁）** |
| **写性能** | 低（全表锁） | 高（无锁，但线程不安全） | **高（细粒度锁，低竞争下接近HashMap）** |
| **Null 键/值** | 不允许 | 允许 | **不允许** |
| **迭代器** | 强一致性 | 快速失败 | **弱一致性** |

**弱一致性解释**：CHM 的迭代器在遍历时，可能不会反映出迭代器创建之后的所有修改，但不会抛出 `ConcurrentModificationException`。这是为了性能而做的权衡，在并发场景下是合理的设计。

### 总结

ConcurrentHashMap 通过以下设计实现了高并发和线程安全：
1.  **数据结构**：采用与 HashMap 相似的 `数组+链表+红黑树`，利用 `volatile` 保证内存可见性。
2.  **无锁读**：通过 `volatile` 读实现，性能极高。
3.  **CAS 写**：在无冲突的场景下（如初始化、插入空桶），使用无锁的 `CAS` 操作，避免线程阻塞。
4.  **细粒度锁**：在发生冲突时，只锁住单个桶的头节点，将锁竞争降到最低。
5.  **协同扩容**：多线程可以协助进行数据迁移，加速扩容过程，避免性能瓶颈。

这种精巧的设计使得 ConcurrentHashMap 成为高并发场景下最优秀、最常用的 Map 实现。

HashMap 是一个在设计和实现上都极其精巧的数据结构，它通过多种技术的结合，在绝大多数情况下都提供了近乎 O(1) 的高效性能。
